{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Title : \n",
    "Churn Prediction Project \n",
    "\n",
    "## Project Description: \n",
    "This project is known as churn prediction for a telecome company.  Imagine that we are working at a telecom company that offers phone and internet\n",
    "services, and we have a problem: some of our customers are churning. They no longer are using our services and are going to a different provider. We would like to prevent that from happening, so we develop a system for identifying these customers and offer them an incentive to stay. We want to target them with promotional messages and give them a discount. We also would like to understand why the model thinks our customers churn, and for that, we need to be able to interpret the model’s predictions.\n",
    " \n",
    "We have collected a dataset where we’ve recorded some information about our customers: what type of services they used, how much they paid, and how long they stayed with us. We also know who canceled their contracts and stopped using our services (churned). We will use this information as the target variable in the machinelearning model and predict it using all other available information. \n",
    "\n",
    "The project plan is as follows: \n",
    "- First, we download the dataset and do some initial preparation: rename columns and change values inside columns to be consistent throughout the entire dataset.\n",
    "- Then we split the data into train, validation, and test so we can validate our models.\n",
    "- As part of the initial data analysis, we look at feature importance to identify which features are important in our data.\n",
    "- We transform categorical variables into numeric variables so we can use them in the model.\n",
    "- Finally, we train a logistic regression model.\n",
    "\n",
    "## Dataset Description\n",
    "- Url:  https://www.kaggle.com/blastchar/telco-customer-churn.\n",
    "\n",
    "- Column description\n",
    "    - CustomerID: the ID of the customer\n",
    "    - Gender: male/female\n",
    "    - SeniorCitizen: whether the customer is a senior citizen (0/1)\n",
    "    - Partner: whether they live with a partner (yes/no)\n",
    "    - Dependents: whether they have dependents (yes/no)\n",
    "    - Tenure: number of months since the start of the contract\n",
    "    - PhoneService: whether they have phone service (yes/no)\n",
    "    - MultipleLines: whether they have multiple phone lines (yes/no/no phone service)\n",
    "    - InternetService: the type of internet service (no/fiber/optic)\n",
    "    - OnlineSecurity: if online security is enabled (yes/no/no internet)\n",
    "    - OnlineBackup: if online backup service is enabled (yes/no/no internet)\n",
    "    - DeviceProtection: if the device protection service is enabled (yes/no/no internet)\n",
    "    - TechSupport: if the customer has tech support (yes/no/no internet)\n",
    "    - StreamingTV: if the TV streaming service is enabled (yes/no/no internet)\n",
    "    - StreamingMovies: if the movie streaming service is enabled (yes/no/no internet)\n",
    "    - Contract: the type of contract (monthly/yearly/two years)\n",
    "    - PaperlessBilling: if the billing is paperless (yes/no)\n",
    "    - PaymentMethod: payment method (electronic check, mailed check, bank transfer, credit card)\n",
    "    - MonthlyCharges: the amount charged monthly (numeric)\n",
    "    - TotalCharges: the total amount charged (numeric)\n",
    "    - Churn: if the client has canceled the contract (yes/no)\n",
    "\n",
    "## Environment Configuration\n",
    "- Installing virtual Env\n",
    "    - pip install pipenv \n",
    "\n",
    "- Installing Packages\n",
    "    - pipenv install jupyter notebook pandas pyarrow numpy matplotlib seaborn scikit-learn\n",
    "\n",
    "- Starting Virtual Env\n",
    "    - pipenv shell \n",
    "\n",
    "- Starting Notebook\n",
    "    - jupyter-notebook \n",
    "\n",
    "- Stoping Notebook \n",
    "    - Ctrl+c\n",
    "\n",
    "- Deactiving Virtual Env\n",
    "    - exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## librarie(s) for loading and preprocessing \n",
    "\n",
    "\n",
    "## libarie(s) for visualization \n",
    "\n",
    "\n",
    "## library for building a validation framwork\n",
    "\n",
    "\n",
    "## library for feature engineering \n",
    "\n",
    "\n",
    "## library for ml algorithms\n",
    "\n",
    "\n",
    "## library for ml metrics \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading And Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load dataset\n",
    "\n",
    "## create a copy of the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## view the first five rows \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## last five rows \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for the total rows and columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for the brief column summary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for missing values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets check for duplicates \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for uniqueness in each column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing \n",
    "- Normalizing the column names \n",
    "- Replacing empty string with nan and fill for missing values \n",
    "- deleted the customer id column \n",
    "- change the data type on the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let convert the the column names to lower case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preview the columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace  values in totalcharges column \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill in the missing values in the totalcharges column with mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete the customer id column \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##del df['customerid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## display the first five rows using the transpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets change the datatype of 'object' columns to category datatypes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets convert the target column, where yes == 1 and no = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets preview the churn column \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis\n",
    "- Target Variable Analysis \n",
    "- Outlier analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets display the distribution of the target column (churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the total counts of each category in the target column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a validation framework\n",
    "- Let’s split the DataFrame such that\n",
    "    - 20% of data goes to validation.\n",
    "    - 20% goes to test.\n",
    "    - The remaining 60% goes to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the dataset into training, validation, and test sets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## print the output of the train, validation, and test data sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select the target column from the dataframe and convert them in matrix format or numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete the target column from the rest of the dataframe \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Training of Logistics Regression Model\n",
    "- To build a baseline model, we use only the numerical featues to train a simple ml algorithm to serve as our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select only numerical featues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the numerical features into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## instantiate a logistic regression algorithm \n",
    "\n",
    "## fit the training data to the algorithm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the validation predictions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## previe the validation predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The predictions of the model: a two-column matrix. \n",
    "- The first column contains  the probability that the target is zero (the client won’t churn). \n",
    "- The second column contains the opposite probability (the target is one, and the client will churn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets select the data in the second column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This output (probabilities) is often called soft predictions. \n",
    "- These tell us the probability of churning as a number between zero and one. It’s up to us to decide how to interpret this number and how to use it.\n",
    "- To make the actual decision about whether to send a promotional letter to our customers, using the probability alone is not enough. \n",
    "- We need hard predictions — binary values of True (churn, so send the mail) or False (not churn, so don’t send the mail).\n",
    "- To get the binary predictions, we take the probabilities and cut them above a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets set the prediction threshold to 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## display the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets compute the acccuracy using the accuracy_score metric \n",
    "\n",
    "\n",
    "## display the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering \n",
    "- transforming all categorical variables to numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets select the categorical, integer and float datatype featues \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets convert the dataframe to a dictionary format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets instantiate the DictVectorizer class\n",
    "\n",
    "\n",
    "## lets train the vectorizer with the train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets transform the training data\n",
    "\n",
    "\n",
    "## lets transform the validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets instantiate a new Logistic regression alg\n",
    "\n",
    "\n",
    "## lets fit the alg with the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets generate the validation prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets generate the churn predictions using a threshold of 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets compute the accurate of the validation predicition using the accuracy_score metrics\n",
    "\n",
    "\n",
    "## lets print the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets import the pickcle libarry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## specifyging where to save the file\n",
    "\n",
    "    ## save the model\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lelts load the saved model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a sample customer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets create a function to make a single prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets call the function to make the prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output the value of the prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets make the prediction by setting the threshold and returning a verdict\n",
    "## 'verdict: Churn' , 'verdict: Not Churn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
