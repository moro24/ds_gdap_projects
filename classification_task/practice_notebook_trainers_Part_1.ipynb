{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Title : \n",
    "Churn Prediction Project \n",
    "\n",
    "## Project Description: \n",
    "This project is known as churn prediction for a telecome company.  Imagine that we are working at a telecom company that offers phone and internet\n",
    "services, and we have a problem: some of our customers are churning. They no longer are using our services and are going to a different provider. We would like to prevent that from happening, so we develop a system for identifying these customers and offer them an incentive to stay. We want to target them with promotional messages and give them a discount. We also would like to understand why the model thinks our customers churn, and for that, we need to be able to interpret the model’s predictions.\n",
    " \n",
    "We have collected a dataset where we’ve recorded some information about our customers: what type of services they used, how much they paid, and how long they stayed with us. We also know who canceled their contracts and stopped using our services (churned). We will use this information as the target variable in the machinelearning model and predict it using all other available information. \n",
    "\n",
    "The project plan is as follows: \n",
    "- First, we download the dataset and do some initial preparation: rename columns and change values inside columns to be consistent throughout the entire dataset.\n",
    "- Then we split the data into train, validation, and test so we can validate our models.\n",
    "- As part of the initial data analysis, we look at feature importance to identify which features are important in our data.\n",
    "- We transform categorical variables into numeric variables so we can use them in the model.\n",
    "- Finally, we train a logistic regression model.\n",
    "\n",
    "## Dataset Description\n",
    "- Url:  https://www.kaggle.com/blastchar/telco-customer-churn.\n",
    "\n",
    "- Column description\n",
    "    - CustomerID: the ID of the customer\n",
    "    - Gender: male/female\n",
    "    - SeniorCitizen: whether the customer is a senior citizen (0/1)\n",
    "    - Partner: whether they live with a partner (yes/no)\n",
    "    - Dependents: whether they have dependents (yes/no)\n",
    "    - Tenure: number of months since the start of the contract\n",
    "    - PhoneService: whether they have phone service (yes/no)\n",
    "    - MultipleLines: whether they have multiple phone lines (yes/no/no phone service)\n",
    "    - InternetService: the type of internet service (no/fiber/optic)\n",
    "    - OnlineSecurity: if online security is enabled (yes/no/no internet)\n",
    "    - OnlineBackup: if online backup service is enabled (yes/no/no internet)\n",
    "    - DeviceProtection: if the device protection service is enabled (yes/no/no internet)\n",
    "    - TechSupport: if the customer has tech support (yes/no/no internet)\n",
    "    - StreamingTV: if the TV streaming service is enabled (yes/no/no internet)\n",
    "    - StreamingMovies: if the movie streaming service is enabled (yes/no/no internet)\n",
    "    - Contract: the type of contract (monthly/yearly/two years)\n",
    "    - PaperlessBilling: if the billing is paperless (yes/no)\n",
    "    - PaymentMethod: payment method (electronic check, mailed check, bank transfer, credit card)\n",
    "    - MonthlyCharges: the amount charged monthly (numeric)\n",
    "    - TotalCharges: the total amount charged (numeric)\n",
    "    - Churn: if the client has canceled the contract (yes/no)\n",
    "\n",
    "## Environment Configuration\n",
    "- Installing virtual Env\n",
    "    - python -m venv venv \n",
    "\n",
    "-  Virtual Env\n",
    "    - source venv/Script/activate\n",
    "\n",
    "\n",
    "- Installing Packages\n",
    "    - pip install jupyter notebook pandas pyarrow numpy matplotlib seaborn scikit-learn\n",
    "\n",
    "- Starting Notebook\n",
    "    - jupyter notebook \n",
    "\n",
    "- Stoping Notebook \n",
    "    - Ctrl+c\n",
    "\n",
    "- Deactiving Virtual Env\n",
    "    - deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## librarie(s) for loading and preprocessing \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "## libarie(s) for visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## library for building a validation framwork\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## library for feature engineering \n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "## library for ml algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## library for ml metrics \n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading And Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load dataset\n",
    "data = pd.read_csv(\"dataset/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "\n",
    "## create a copy of the \n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## view the first five rows \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## last five rows \n",
    "df.tail().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for the total rows and columns \n",
    "print(f'total number of rows: {df.shape[0]} => total number of columns: {df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for the brief column summary \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for the datatypes in each column \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for missing values \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets check for duplicates \n",
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for uniqueness in each column ## use  same approach for other columns \n",
    "np.unique(df['TotalCharges'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing \n",
    "- Normalizing the column names \n",
    "- Replacing empty string with nan and fill for missing values \n",
    "- deleted the customer id column \n",
    "- change the data type on the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let convert the the column names to lower case\n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preview the columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace  values in totalcharges column \n",
    "df.totalcharges = pd.to_numeric(df.totalcharges, errors='coerce') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for missing values \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill in the missing values in the totalcharges column with mean\n",
    "\n",
    "df.totalcharges = df.totalcharges.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete the customer id column \n",
    "del df['customerid']\n",
    "\n",
    "# ## delete the customer id column \n",
    "# df = df.drop(['customerid'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## display the first five rows using the transpose\n",
    "df.churn.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets change the datatype of 'object' columns to category datatypes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets convert the target column, where yes == 1 and no = 0\n",
    "df.churn = (df.churn == 'Yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets preview the churn column \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis\n",
    "- Target Variable Analysis \n",
    "- Outlier analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets display the distribution of the target column (churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the total counts of each category in the target column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a validation framework\n",
    "- Let’s split the DataFrame such that\n",
    "    - 20% of data goes to validation.\n",
    "    - 20% goes to test.\n",
    "    - The remaining 60% goes to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the dataset into training, validation, and test sets\n",
    "df_train_full , df_test = train_test_split(df, test_size=0.2, random_state=11) \n",
    "df_train, df_valid = train_test_split(df_train_full, test_size=0.25, random_state=11)\n",
    "\n",
    "\n",
    "## print the output of the train, validation, and test data sample\n",
    "print(f'Training dataset: {len(df_train)}')\n",
    "print(f'Validation dataset: {len(df_valid)}')\n",
    "print(f'Test dataset: {len(df_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select the target column from the dataframe and convert them in matrix format or numpy array\n",
    "y_train = df_train['churn'].values\n",
    "y_valid = df_valid['churn'].values\n",
    "y_test = df_test['churn'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete the target column from the rest of the dataframe \n",
    "del df_train['churn']\n",
    "del df_valid['churn']\n",
    "del df_test['churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Training of Logistics Regression Model\n",
    "- To build a baseline model, we use only the numerical featues to train a simple ml algorithm to serve as our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select only numerical featues \n",
    "df_train_bl = df_train.select_dtypes(exclude=[object])\n",
    "df_valid_bl = df_valid.select_dtypes(exclude=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the numerical features into numpy array\n",
    "X_train_bl = df_train_bl.values\n",
    "X_valid_bl = df_valid_bl.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## instantiate a logistic regression algorithm \n",
    "bl_model = LogisticRegression(solver='liblinear', random_state=1)\n",
    "\n",
    "## fit the training data to the algorithm \n",
    "bl_model.fit(X_train_bl, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the validation predictions \n",
    "y_valid_pred_bl = bl_model.predict_proba(X_valid_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preview the validation predictions\n",
    "y_valid_pred_bl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The predictions of the model: a two-column matrix. \n",
    "- The first column contains  the probability that the target is zero (the client won’t churn). \n",
    "- The second column contains the opposite probability (the target is one, and the client will churn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets select the data in the second column\n",
    "y_valid_pred = bl_model.predict_proba(X_valid_bl)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This output (probabilities) is often called soft predictions. \n",
    "- These tell us the probability of churning as a number between zero and one. It’s up to us to decide how to interpret this number and how to use it.\n",
    "- To make the actual decision about whether to send a promotional letter to our customers, using the probability alone is not enough. \n",
    "- We need hard predictions — binary values of True (churn, so send the mail) or False (not churn, so don’t send the mail).\n",
    "- To get the binary predictions, we take the probabilities and cut them above a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets set the prediction threshold to 0.5\n",
    "churn = y_valid_pred >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # display the output\n",
    "# (y_valid == churn).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets compute the acccuracy using the accuracy_score metric \n",
    "acc_score = accuracy_score(y_valid_pred_bl, churn)\n",
    "\n",
    "## display the output\n",
    "print(f'Baseline Validation Accuracy Score: {round(acc_score * 100, 1)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
